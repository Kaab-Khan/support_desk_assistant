================================================================================
    AI SUPPORT DESK ASSISTANT - COMPLETE PROJECT ARCHITECTURE
    Complete Technical Documentation & Working Guide
================================================================================

Project Version: 0.1.0
Last Updated: December 29, 2024
Architecture: Clean Architecture with Layered Design
Status: Production-Ready with Complete Test Coverage (101 Tests - All Passing)

================================================================================
TABLE OF CONTENTS
================================================================================

1. PROJECT OVERVIEW
2. ARCHITECTURE DESIGN
3. CURRENT DIRECTORY STRUCTURE
4. CORE COMPONENTS & IMPLEMENTATION
5. API ENDPOINTS (4 ENDPOINTS)
6. DATABASE SCHEMA
7. EXTERNAL INTEGRATIONS
8. TESTING INFRASTRUCTURE
9. CONFIGURATION & DEPLOYMENT
10. COMPLETE DATA FLOWS

================================================================================
1. PROJECT OVERVIEW
================================================================================

The AI Support Desk Assistant is an enterprise-grade FastAPI application that
automates support ticket triage using RAG (Retrieval-Augmented Generation),
LLM-powered decision making, and vector similarity search.

KEY FEATURES:
-------------
âœ“ Automated ticket processing with AI-powered triage
âœ“ RAG-based knowledge base search using Pinecone vector store
âœ“ Intelligent action recommendation (reply/escalate/close)
âœ“ Tag extraction integrated into RAG workflow
âœ“ Client-side conversation memory for multi-turn dialogues
âœ“ Human feedback loop for continuous improvement
âœ“ RESTful API with versioning (v1)
âœ“ SQLite database for ticket persistence
âœ“ Comprehensive test suite (101 tests)
âœ“ Production-ready architecture with dependency injection

IMPORTANT NOTE:
---------------
There is NO separate summarizer service. All summarization and tag extraction
is handled directly by the RAG service in a single LLM call for efficiency.
The OpenAI client has a generate_summary_with_tags() method but it's only
used in tests, not in production endpoints.

TECHNOLOGY STACK:
-----------------
â€¢ Backend Framework: FastAPI 0.115.5
â€¢ Language: Python 3.10+
â€¢ Database: SQLite with SQLAlchemy 2.0.23 ORM
â€¢ Vector Store: Pinecone Cloud (Serverless AWS us-east-1)
â€¢ LLM Provider: OpenAI (GPT-4o-mini)
â€¢ Embeddings: OpenAI text-embedding-ada-002 (1536 dimensions)
â€¢ Testing: pytest with 78 tests (unit + integration)
â€¢ Server: Uvicorn ASGI server
â€¢ Dependencies: pydantic, pydantic-settings, python-dotenv

================================================================================
2. ARCHITECTURE DESIGN
================================================================================

ARCHITECTURAL PATTERN: Clean Architecture + Layered Design
-----------------------------------------------------------

The project follows Clean Architecture principles with clear separation of
concerns across layers:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         API LAYER                                â”‚
â”‚                    (app/api/v1/)                                 â”‚
â”‚  â€¢ HTTP request/response handling                                â”‚
â”‚  â€¢ Input validation with Pydantic schemas                        â”‚
â”‚  â€¢ RESTful endpoint definitions                                  â”‚
â”‚  â€¢ Dependency injection                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CORE LAYER                                  â”‚
â”‚                   (app/core/)                                    â”‚
â”‚  â€¢ Business logic and workflows                                  â”‚
â”‚  â€¢ Service orchestration (RAG service)                           â”‚
â”‚  â€¢ Workflow coordination (Ticket workflow)                       â”‚
â”‚  â€¢ LLM prompt management (future)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                       â”‚
             â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INFRASTRUCTURE    â”‚    â”‚      CONFIGURATION                   â”‚
â”‚  (app/infrastructure/) â”‚ â”‚      (app/config/)                  â”‚
â”‚  â€¢ Database         â”‚    â”‚  â€¢ Environment settings              â”‚
â”‚  â€¢ Vector stores    â”‚    â”‚  â€¢ API keys management               â”‚
â”‚  â€¢ External clients â”‚    â”‚  â€¢ Database URLs                     â”‚
â”‚  â€¢ Repositories     â”‚    â”‚  â€¢ Directory paths                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SCHEMAS LAYER                               â”‚
â”‚                   (app/schemas/)                                 â”‚
â”‚  â€¢ Pydantic request models                                       â”‚
â”‚  â€¢ Pydantic response models                                      â”‚
â”‚  â€¢ LLM prompt templates (RagPrompts, PromptValidator)            â”‚
â”‚  â€¢ Validation rules                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DEPENDENCY FLOW:
----------------
API Layer â†’ Core Layer â†’ Infrastructure Layer
         â†“
      Schemas Layer (shared across all layers)
         â†“
      Config Layer (shared across all layers)

KEY PRINCIPLE: Inner layers (Core) don't depend on outer layers (API/Infrastructure)

================================================================================
3. CURRENT DIRECTORY STRUCTURE
================================================================================

support_desk_assistant-1/
â”‚
â”œâ”€â”€ ðŸ“ app/                           # Main application package (28 Python files)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                       # FastAPI app entry point + health check
â”‚   â”‚
â”‚   â”œâ”€â”€ ðŸ“ api/                       # API Layer (HTTP handlers)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dependencies.py           # Dependency injection (get_db, get_rag, get_ticket_agent)
â”‚   â”‚   â””â”€â”€ v1/                       # API version 1
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ endpoints.py          # 4 REST endpoints (rag, tickets)
â”‚   â”‚
â”‚   â”œâ”€â”€ ðŸ“ core/                      # Core Business Logic Layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ services/                 # Business services
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ rag_service.py        # RAG implementation with tag extraction
â”‚   â”‚   â”œâ”€â”€ workflows/                # Workflow orchestrators
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ ticket_workflow.py    # Ticket processing orchestration
â”‚   â”‚   â””â”€â”€ llm/                      # LLM configurations (currently empty)
â”‚   â”‚       â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ðŸ“ infrastructure/            # Infrastructure Layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ db/                       # Database
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ connection.py         # SQLAlchemy setup + init_db()
â”‚   â”‚   â”‚   â””â”€â”€ models.py             # Ticket ORM model
â”‚   â”‚   â”œâ”€â”€ repositories/             # Data access layer
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ ticket_repository.py  # CRUD operations (create, get, list, update_feedback)
â”‚   â”‚   â”œâ”€â”€ vectorstores/             # Vector database clients
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ pinecone_client.py    # Pinecone integration (VectorStoreClient)
â”‚   â”‚   â””â”€â”€ clients/                  # External API clients
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ openai_client.py      # OpenAI API wrapper (OpenAIClient)
â”‚   â”‚
â”‚   â”œâ”€â”€ ðŸ“ config/                    # Configuration Layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ settings.py               # Settings class with environment variables
â”‚   â”‚
â”‚   â””â”€â”€ ðŸ“ schemas/                   # Schemas Layer
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ requests.py               # RagQueryRequest, TicketAgentRequest, TicketFeedbackRequest
â”‚       â”œâ”€â”€ responses.py              # RagQueryResponse, TicketAgentResponse, TicketRecord, RagSource
â”‚       â””â”€â”€ prompts.py                # RagPrompts class + PromptValidator
â”‚
â”œâ”€â”€ ðŸ“ tests/                         # Test Suite (78 tests total)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                   # Pytest configuration + fixtures
â”‚   â”œâ”€â”€ unit/                         # Unit tests (mocked dependencies)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ test_rag_service.py
â”‚   â”‚   â”‚   â””â”€â”€ workflows/
â”‚   â”‚   â”‚       â””â”€â”€ test_ticket_workflow.py
â”‚   â”‚   â””â”€â”€ infrastructure/
â”‚   â”‚       â”œâ”€â”€ clients/
â”‚   â”‚       â”‚   â””â”€â”€ test_openai_client.py
â”‚   â”‚       â”œâ”€â”€ vectorstores/
â”‚   â”‚       â”‚   â””â”€â”€ test_pinecone_client.py
â”‚   â”‚       â””â”€â”€ repositories/
â”‚   â”‚           â””â”€â”€ test_ticket_repository.py
â”‚   â””â”€â”€ integration/                  # Integration tests (real services)
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ api/
â”‚       â”‚   â””â”€â”€ test_tickets_endpoint.py  # 11 tests
â”‚       â”œâ”€â”€ test_database_integration.py   # 10 tests
â”‚       â”œâ”€â”€ test_openai_integration.py     # 12 tests (including generate_summary_with_tags)
â”‚       â”œâ”€â”€ test_pinecone_connection.py    # 2 tests
â”‚       â”œâ”€â”€ test_rag_integration.py        # 5 tests
â”‚       â””â”€â”€ test_end_to_end.py             # 2 tests
â”‚
â”œâ”€â”€ ðŸ“ scripts/                       # Utility scripts
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ ingest_docs.py                # Document ingestion to Pinecone
â”‚
â”œâ”€â”€ ðŸ“ data/                          # Data storage
â”‚   â”œâ”€â”€ docs/                         # Knowledge base documents (.txt, .md)
â”‚   â”œâ”€â”€ database/                     # Database backup directory
â”‚   â”œâ”€â”€ logs/                         # Application logs directory
â”‚   â”œâ”€â”€ support.db                    # Production SQLite database
â”‚   â””â”€â”€ test_support.db               # Test SQLite database
â”‚
â”œâ”€â”€ ðŸ“ docs/                          # Documentation
â”‚   â”œâ”€â”€ OPENAI_CLIENT_REFACTOR.md     # OpenAI client refactoring notes
â”‚   â””â”€â”€ OPTIMIZATION_RAG_CONSOLIDATION.md  # RAG consolidation optimization
â”‚
â”œâ”€â”€ ðŸ“„ requirements.txt               # Production dependencies (9 packages)
â”œâ”€â”€ ðŸ“„ requirements-dev.txt           # Development dependencies
â”œâ”€â”€ ðŸ“„ pytest.ini                     # Pytest configuration
â”œâ”€â”€ ðŸ“„ Makefile                       # Development commands
â”œâ”€â”€ ðŸ“„ .env                           # Environment variables (gitignored)
â”œâ”€â”€ ðŸ“„ .gitignore                     # Git ignore rules
â”œâ”€â”€ ðŸ“„ close_db.py                    # Database cleanup utility script
â”œâ”€â”€ ðŸ“„ DATABASE_USAGE.md              # Database access guide
â”œâ”€â”€ ðŸ“„ test_coverage_analysis.txt     # Test coverage analysis
â””â”€â”€ ðŸ“„ README.md                      # Project overview (if exists)

TOTAL: 28 Python files in app/, 78 test files, 11 test files

================================================================================
4. CORE COMPONENTS & IMPLEMENTATION
================================================================================

4.1 TICKET PROCESSING WORKFLOW
-------------------------------

Entry Point: POST /api/v1/tickets/agent

Components Involved:
â€¢ app/api/v1/endpoints.py â†’ process_ticket()
â€¢ app/core/workflows/ticket_workflow.py â†’ TicketAgentService.process_ticket()
â€¢ app/core/services/rag_service.py â†’ RagService.answer()
â€¢ app/infrastructure/vectorstores/pinecone_client.py â†’ VectorStoreClient.query_similar()
â€¢ app/infrastructure/clients/openai_client.py â†’ OpenAIClient.generate_rag_response()
â€¢ app/infrastructure/repositories/ticket_repository.py â†’ create_ticket()
â€¢ app/infrastructure/db/models.py â†’ Ticket (ORM)

Processing Flow:
1. Client sends ticket text via POST request
2. FastAPI endpoint validates request (TicketAgentRequest schema)
3. TicketAgentService.process_ticket() is called with db session and text
4. RAG service is invoked: rag_service.answer(text)
   â†’ This single call returns: {answer, tags, confidence, sources}
5. Action determination logic:
   - IF answer exists and not "INSUFFICIENT_CONTEXT" â†’ action = "reply"
   - ELSE â†’ action = "escalate"
6. Ticket persisted to database with:
   - text, action, reply (if action=reply), tags, reason
7. Response returned: {id, action, reply, tags, reason}

IMPORTANT: There is NO separate summarization step. Tags are extracted
during the RAG call using structured JSON output from OpenAI.

4.2 RAG SERVICE (CORE LOGIC)
-----------------------------

Purpose: Answer queries using knowledge base with integrated tag extraction

Location: app/core/services/rag_service.py

Class: RagService

Dependencies:
â€¢ VectorStoreClient (Pinecone)
â€¢ OpenAIClient

Key Method: answer(query: str, top_k: int = 5)

Workflow:
1. Query received
2. VectorStore retrieves top_k similar documents (default 5)
   - Generates embedding for query
   - Performs cosine similarity search in Pinecone
   - Returns matches with metadata
3. Context building:
   - Extracts text snippets from matched documents
   - Formats as numbered context list
4. LLM generation:
   - Calls OpenAIClient.generate_rag_response(query, context_chunks)
   - Uses structured prompt from RagPrompts
   - Returns JSON: {answer, tags, confidence}
5. Returns complete result dict with sources

Return Format:
{
    "answer": "The generated answer text...",
    "tags": ["tag1", "tag2", "tag3"],
    "confidence": "high"|"medium"|"low",
    "sources": [
        {
            "id": "doc_id",
            "score": 0.95,
            "metadata": {"source": "file.txt", "text": "snippet..."}
        }
    ]
}

Singleton Pattern: get_rag_service() returns cached instance

4.3 OPENAI CLIENT
-----------------

Purpose: Centralized OpenAI API wrapper

Location: app/infrastructure/clients/openai_client.py

Class: OpenAIClient

Configuration:
â€¢ API Key: From settings.OPENAI_API_KEY
â€¢ Default Model: gpt-4o-mini
â€¢ Client: OpenAI SDK v1.3.7

Key Methods:

1. generate_chat_completion(messages, model, temperature, max_tokens)
   - Basic chat completion
   - Returns: str (response text)

2. generate_embeddings(texts, model="text-embedding-ada-002")
   - Batch embedding generation
   - Returns: List[List[float]] (1536-dimensional vectors)

3. generate_rag_response(query, context_chunks, model)
   - Specialized RAG generation with structured output
   - Uses RagPrompts.SYSTEM_PROMPT_WITH_TAGS and user prompt
   - Parses JSON response
   - Returns: Dict[str, Any] with {answer, tags, confidence}
   - Fallback to plain text if JSON parsing fails

4. generate_summary_with_tags(text, max_sentences, model)
   - Summarization utility (ONLY used in tests, NOT in production endpoints)
   - Returns: str (JSON formatted)

Singleton Pattern: get_openai_client() returns cached instance

4.4 PINECONE VECTOR STORE CLIENT
---------------------------------

Purpose: Manage document embeddings and similarity search

Location: app/infrastructure/vectorstores/pinecone_client.py

Class: VectorStoreClient

Configuration:
â€¢ Cloud: AWS
â€¢ Region: us-east-1
â€¢ Spec: ServerlessSpec
â€¢ Index Name: From settings.PINECONE_INDEX_NAME
â€¢ Dimension: 1536 (OpenAI ada-002 embedding size)
â€¢ Metric: Cosine similarity

Initialization:
â€¢ Connects to existing index or creates new one
â€¢ Auto-creates index if doesn't exist

Key Methods:

1. upsert_documents(texts, metadatas, ids, namespace)
   - Generates embeddings for texts using OpenAI
   - Upserts vectors to Pinecone with metadata
   - Supports custom IDs or auto-generation
   - Supports namespaces for organization

2. query_similar(query_text, top_k=5, namespace)
   - Generates embedding for query
   - Searches Pinecone for similar vectors
   - Returns matches with scores and metadata
   - Format: List[Dict] with id, score, metadata

3. delete_all(namespace)
   - Deletes all vectors in namespace
   - Used for cleanup/testing

Metadata Structure:
{
    "source": "filename.txt",
    "text": "document chunk text"
}

Singleton Pattern: get_vectorstore_client() returns cached instance

4.5 DATABASE & REPOSITORY LAYER
--------------------------------

Database: SQLite with SQLAlchemy ORM

Files:
â€¢ app/infrastructure/db/connection.py - Database setup
â€¢ app/infrastructure/db/models.py - ORM models
â€¢ app/infrastructure/repositories/ticket_repository.py - CRUD operations

Database Configuration:
â€¢ URL: sqlite:///data/support.db (configurable via DB_URL)
â€¢ Pooling: NullPool (disabled for SQLite)
â€¢ Auto-create tables: init_db() called on app startup

Ticket Model (ORM):
-------------------
Table: tickets

Columns:
â€¢ id: Integer, Primary Key, AutoIncrement
â€¢ text: Text, NOT NULL (ticket content)
â€¢ action: String, NOT NULL (reply/escalate/close)
â€¢ reply: Text, Nullable (AI-generated response)
â€¢ tags: String, Nullable (comma-separated tags)
â€¢ reason: Text, Nullable (explanation for action)
â€¢ created_at: DateTime, NOT NULL, Default NOW
â€¢ human_label: String, Nullable (feedback label)

Repository Operations (ticket_repository.py):
----------------------------------------------

1. create_ticket(db, text, action, reply, tags, reason, human_label)
   - Tags: List[str] â†’ converted to comma-separated string
   - Returns: Ticket ORM object with ID

2. get_ticket(db, ticket_id)
   - Returns: Ticket or None

3. list_tickets(db, skip=0, limit=100)
   - Pagination support
   - Returns: List[Ticket]

4. update_ticket_feedback(db, ticket_id, human_label)
   - Updates human_label field
   - Returns: Updated Ticket or None

Database Cleanup:
â€¢ close_db.py script for releasing locks
â€¢ Important for SQLite when using external tools

4.6 TICKET WORKFLOW SERVICE
----------------------------

Purpose: Orchestrate ticket processing workflow

Location: app/core/workflows/ticket_workflow.py

Class: TicketAgentService

Dependencies:
â€¢ RagService (for analysis)

Process Logic (process_ticket method):
---------------------------------------
1. Call RAG service with ticket text
2. Extract: answer, tags, confidence from RAG result
3. Determine action:
   - IF answer exists AND not "INSUFFICIENT_CONTEXT" â†’ action = "reply"
   - ELSE â†’ action = "escalate"
4. Set reason:
   - For reply: "Generated reply using knowledge base context via RAG."
   - For escalate: Explains lack of context
5. Create ticket in database
6. Return: {id, action, reply, tags, reason}

Note: No separate summarization or tag extraction step.
Everything happens in ONE RAG call for efficiency.

Singleton Pattern: get_ticket_agent_service() returns cached instance

================================================================================
5. API ENDPOINTS (4 ENDPOINTS)
================================================================================

Base URL: http://localhost:8000
API Version: v1
Prefix: /api/v1

HEALTH CHECK ENDPOINT
---------------------
GET /health

Description: Service health check
Authentication: None
Response: {"status": "healthy", "version": "0.1.0"}
Status Codes: 200 OK

5.1 RAG QUERY ENDPOINT
----------------------
POST /api/v1/rag/query

Description: Query the knowledge base using RAG with optional conversation history
Authentication: None

Request Schema (RagQueryRequest):
{
  "query": "How do I reset my password?"
}

With Conversation History (for follow-up questions):
{
  "query": "What about the second step?",
  "conversation_history": [
    {
      "role": "user",
      "content": "How do I reset my password?"
    },
    {
      "role": "assistant",
      "content": "Follow these steps: 1. Go to Settings..."
    }
  ]
}

Validation:
â€¢ query: string, required, non-empty, stripped
â€¢ conversation_history: optional array of ConversationMessage objects
  - role: "user" | "assistant"
  - content: string

Response Schema (RagQueryResponse):
{
  "answer": "To reset your password, go to Settings > Account > Reset Password...",
  "sources": [
    {
      "doc_name": "password_reset.txt",
      "snippet": "Password reset instructions: Navigate to..."
    }
  ]
}

Conversation Memory Strategy:
â€¢ Client-side stateless memory (no server storage)
â€¢ Client maintains conversation history locally
â€¢ Last 6 messages (3 turns) are summarized and included in RAG prompt
â€¢ Long messages truncated to 150 characters in summary
â€¢ Automatic token management to control API costs
â€¢ Works with free Render tier (no persistent storage needed)

Status Codes:
â€¢ 200 OK - Success
â€¢ 422 Unprocessable Entity - Validation error

Handler: rag_query() in endpoints.py
Dependencies: RagService (via get_rag)

5.2 PROCESS TICKET ENDPOINT
---------------------------
POST /api/v1/tickets/agent

Description: Process a support ticket with AI triage
Authentication: None

Request Schema (TicketAgentRequest):
{
  "ticket": "My account is locked and I can't login"
}

Response Schema (TicketAgentResponse):
{
  "id": 1,
  "action": "reply",
  "reply": "I can help you unlock your account. Please follow these steps...",
  "reason": "Generated reply using knowledge base context via RAG.",
  "tags": ["account", "locked", "authentication"]
}

Fields:
â€¢ id: Ticket database ID
â€¢ action: "reply" | "escalate" | "close"
â€¢ reply: Generated response (null if escalated)
â€¢ reason: Explanation for the action
â€¢ tags: List of extracted tags

Status Codes:
â€¢ 200 OK - Success
â€¢ 422 Unprocessable Entity - Validation error

Handler: process_ticket() in endpoints.py
Dependencies: Database session, TicketAgentService

5.3 SUBMIT FEEDBACK ENDPOINT
-----------------------------
POST /api/v1/tickets/feedback

Description: Submit human feedback for a ticket (human-in-the-loop)
Authentication: None

Request Schema (TicketFeedbackRequest):
{
  "ticket_id": 1,
  "human_label": "correct"
}

Valid Labels:
â€¢ "correct" - Agent decision was correct
â€¢ "wrong_action" - Wrong action chosen
â€¢ "wrong_reply" - Wrong reply generated  
â€¢ "needs_improvement" - Reply needs improvement

Response Schema (TicketRecord):
{
  "id": 1,
  "text": "My account is locked...",
  "action": "reply",
  "reply": "I can help you...",
  "tags": ["account", "locked", "authentication"],
  "reason": "Generated reply using knowledge base context via RAG.",
  "created_at": "2024-12-27T09:59:00",
  "human_label": "correct"
}

Status Codes:
â€¢ 200 OK - Success
â€¢ 404 Not Found - Ticket ID doesn't exist
â€¢ 422 Unprocessable Entity - Validation error

Handler: submit_ticket_feedback() in endpoints.py
Dependencies: Database session
Repository: ticket_repository.update_ticket_feedback()

5.4 LIST TICKETS ENDPOINT
-------------------------
GET /api/v1/tickets

Description: Retrieve paginated list of tickets
Authentication: None

Query Parameters:
â€¢ skip: int = 0 (number of records to skip)
â€¢ limit: int = 50 (maximum records to return)

Example: GET /api/v1/tickets?skip=0&limit=10

Response Schema: List[TicketRecord]
[
  {
    "id": 1,
    "text": "My account is locked",
    "action": "reply",
    "reply": "I can help you...",
    "tags": ["account", "locked"],
    "reason": "Generated reply using knowledge base context via RAG.",
    "created_at": "2024-12-27T09:59:00",
    "human_label": "correct"
  }
]

Status Codes:
â€¢ 200 OK - Success

Handler: list_tickets() in endpoints.py
Dependencies: Database session
Repository: ticket_repository.list_tickets()

NOTE: There is NO /api/v1/summarise endpoint in the current implementation.
Tag extraction happens during RAG processing, not as a separate endpoint.

================================================================================
6. DATABASE SCHEMA
================================================================================

Database Type: SQLite
Production Location: data/support.db
Test Location: data/test_support.db
ORM: SQLAlchemy 2.0.23

TICKETS TABLE
-------------

CREATE TABLE tickets (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    text TEXT NOT NULL,
    action VARCHAR NOT NULL,
    reply TEXT,
    tags VARCHAR,
    reason TEXT,
    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    human_label VARCHAR
);

Field Details:
--------------
id:
  - Type: INTEGER
  - Constraint: PRIMARY KEY, AUTOINCREMENT
  - Description: Unique ticket identifier

text:
  - Type: TEXT
  - Constraint: NOT NULL
  - Description: Original ticket content submitted by user

action:
  - Type: VARCHAR
  - Constraint: NOT NULL
  - Values: "reply", "escalate", "close"
  - Description: AI-recommended action

reply:
  - Type: TEXT
  - Constraint: NULLABLE
  - Description: AI-generated response (NULL if escalated)

tags:
  - Type: VARCHAR
  - Constraint: NULLABLE
  - Format: Comma-separated string (e.g., "account,password,login")
  - Description: Tags extracted by LLM during RAG processing

reason:
  - Type: TEXT
  - Constraint: NULLABLE
  - Description: Explanation for why this action was chosen

created_at:
  - Type: DATETIME
  - Constraint: NOT NULL
  - Default: CURRENT_TIMESTAMP
  - Description: Timestamp when ticket was created

human_label:
  - Type: VARCHAR
  - Constraint: NULLABLE
  - Values: "correct", "wrong_action", "wrong_reply", "needs_improvement"
  - Description: Human feedback label

Access Patterns:
----------------
â€¢ CREATE: High frequency (every ticket submission)
â€¢ READ by ID: Medium frequency (feedback submission)
â€¢ LIST: Low frequency (admin/monitoring)
â€¢ UPDATE: Low frequency (feedback updates only)

Indexes:
--------
â€¢ PRIMARY KEY on id (automatic)

Database Management:
--------------------
â€¢ Connection pooling: Disabled (NullPool for SQLite)
â€¢ Auto-create: init_db() creates table if not exists
â€¢ Cleanup: close_db.py script to release locks
â€¢ WAL mode: Can be enabled for better concurrency

================================================================================
7. EXTERNAL INTEGRATIONS
================================================================================

7.1 OPENAI API INTEGRATION
---------------------------

Provider: OpenAI
API Version: v1.3.7 (SDK version)
Authentication: API Key via environment variable

Models Used:
------------
1. gpt-4o-mini
   - Purpose: Chat completions for RAG and ticket triage
   - Context: Up to 128K tokens
   - Output: JSON-structured responses
   - Temperature: 0.7 (default, configurable)

2. text-embedding-ada-002
   - Purpose: Generate embeddings for documents and queries
   - Output: 1536-dimensional vectors
   - Use cases: Document ingestion, query embedding

Configuration:
--------------
â€¢ API Key: settings.OPENAI_API_KEY (from .env)
â€¢ Default Model: gpt-4o-mini (configurable)
â€¢ Timeout: Default (uses SDK defaults)
â€¢ Retry Logic: Built into OpenAI SDK

Usage Patterns:
---------------
â€¢ Embeddings: 
  - Every RAG query (1 call per query)
  - Document ingestion (batch calls during ingest_docs.py)

â€¢ Chat Completions:
  - Every ticket processing (1 call per ticket)
  - Every RAG query (1 call per query)

â€¢ Average tokens per request: 500-1500 tokens

Cost Optimization:
------------------
â€¢ Using cost-efficient gpt-4o-mini model
â€¢ Caching embeddings in Pinecone (no re-computation)
â€¢ Structured JSON output reduces parsing complexity
â€¢ Single LLM call per ticket (no separate summarization)

Error Handling:
---------------
â€¢ JSON parsing fallback if structured output fails
â€¢ Returns safe defaults on errors
â€¢ Logs errors for monitoring

7.2 PINECONE VECTOR DATABASE
-----------------------------

Provider: Pinecone Systems
Type: Serverless vector database
API Version: pinecone-client 5.0.1

Configuration:
--------------
â€¢ Cloud: AWS
â€¢ Region: us-east-1
â€¢ Spec: ServerlessSpec (auto-scaling)
â€¢ Index Name: settings.PINECONE_INDEX_NAME (from .env)
â€¢ Dimension: 1536 (matches OpenAI ada-002)
â€¢ Metric: Cosine similarity

Authentication:
---------------
â€¢ API Key: settings.PINECONE_API_KEY (from .env)

Index Operations:
-----------------
â€¢ Auto-creation: Creates index if doesn't exist on first run
â€¢ Upsert: Batch document ingestion with metadata
â€¢ Query: Similarity search with top-k retrieval
â€¢ Delete: Namespace-based cleanup

Data Structure:
---------------
Vector ID: Auto-generated or custom string
Vector: [1536 floats] - embedding from OpenAI
Metadata:
  {
    "source": "filename.txt",
    "text": "document chunk content..."
  }

Performance:
------------
â€¢ Query latency: < 100ms typical
â€¢ Capacity: Unlimited (serverless auto-scaling)
â€¢ Concurrent queries: Auto-scaled
â€¢ Cost: Pay-per-use (serverless pricing)

Usage Patterns:
---------------
â€¢ Document Ingestion:
  - Run scripts/ingest_docs.py
  - Chunks documents, generates embeddings, upserts to Pinecone
  
â€¢ Query Processing:
  - Every RAG query searches Pinecone
  - Returns top-5 similar documents
  - Used for ticket processing and direct RAG queries

Namespace Strategy:
-------------------
â€¢ Default: No namespace (empty string)
â€¢ Can organize by: document type, tenant, environment

Error Handling:
---------------
â€¢ Connection errors logged and raised
â€¢ Retry logic in Pinecone SDK
â€¢ Graceful degradation on failure

================================================================================
8. TESTING INFRASTRUCTURE
================================================================================

Testing Framework: pytest 8.3.4
Total Tests: 78 tests
Results: 77 passed, 1 skipped
Coverage: Comprehensive (unit + integration)
Duration: ~45 seconds

Test Configuration (pytest.ini):
---------------------------------
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
asyncio_mode = strict

Test Fixtures (conftest.py):
-----------------------------
â€¢ test_db: Test database session with NullPool
â€¢ client: FastAPI TestClient
â€¢ mock_openai: Mocked OpenAIClient
â€¢ mock_pinecone: Mocked VectorStoreClient
â€¢ sample_tickets: Test data fixtures

Cleanup Hooks:
--------------
â€¢ pytest_sessionfinish: Closes all database connections after tests
â€¢ Garbage collection forced to release database locks

UNIT TESTS (tests/unit/)
-------------------------
Focus: Test individual components in isolation with mocks

1. Core Services Tests
   â€¢ tests/unit/core/services/test_rag_service.py
     - RAG service initialization
     - Query processing with mocked dependencies
     - Context building logic
     - Error handling scenarios
     
2. Core Workflows Tests
   â€¢ tests/unit/core/workflows/test_ticket_workflow.py
     - Ticket processing logic
     - Action determination (reply vs escalate)
     - Reply generation
     - Edge cases (empty tickets, malformed data)

3. Infrastructure Clients Tests
   â€¢ tests/unit/infrastructure/clients/test_openai_client.py
     - Chat completion generation
     - Embedding generation
     - RAG response generation
     - JSON parsing and validation
     - Error handling
   
   â€¢ tests/unit/infrastructure/vectorstores/test_pinecone_client.py
     - Index initialization
     - Document upsertion
     - Similarity search
     - Namespace operations
     - Batch processing

4. Repository Tests
   â€¢ tests/unit/infrastructure/repositories/test_ticket_repository.py
     - Create ticket operation
     - Get ticket by ID
     - List tickets with pagination
     - Update feedback
     - Data validation

INTEGRATION TESTS (tests/integration/)
---------------------------------------
Focus: Test component interactions with real or semi-real services

1. API Endpoint Tests (11 tests)
   â€¢ tests/integration/api/test_tickets_endpoint.py
     - POST /api/v1/tickets/agent success scenarios
     - POST /api/v1/tickets/agent failure scenarios
     - POST /api/v1/tickets/feedback success/failure
     - GET /api/v1/tickets with pagination
     - Input validation edge cases
     - Error response formats
     - Integration with database

2. Database Integration Tests (10 tests)
   â€¢ tests/integration/test_database_integration.py
     - Database file creation
     - Schema validation (tables, columns)
     - CRUD operations end-to-end
     - Persistence verification
     - Feedback update workflow
     - Pagination correctness
     - Tags storage format (comma-separated)
     - Database constraints
     - Connection cleanup

3. OpenAI Integration Tests (12 tests)
   â€¢ tests/integration/test_openai_integration.py
     - Real OpenAI API connectivity
     - Chat completion generation
     - Chat completion with custom parameters
     - Single text embedding
     - Multiple text embeddings (batch)
     - RAG response with context
     - RAG response with empty context
     - generate_summary_with_tags() method (test-only)
     - JSON parsing from OpenAI responses
     - Error handling with API failures

4. Pinecone Integration Tests (2 tests)
   â€¢ tests/integration/test_pinecone_connection.py
     - Pinecone client initialization
     - Query operations with real Pinecone instance

5. RAG Integration Tests (5 tests)
   â€¢ tests/integration/test_rag_integration.py
     - End-to-end RAG workflow
     - Vector store + OpenAI integration
     - Tag extraction during RAG
     - Source attribution
     - Error propagation

6. End-to-End Tests (2 tests)
   â€¢ tests/integration/test_end_to_end.py
     - Complete ticket workflow from API to database
     - Health check endpoint

Running Tests:
--------------
# All tests
pytest tests/ -v

# Only unit tests
pytest tests/unit/ -v

# Only integration tests
pytest tests/integration/ -v

# Specific test file
pytest tests/integration/test_end_to_end.py -v

# With coverage report
pytest tests/ --cov=app --cov-report=html

# Parallel execution
pytest tests/ -n auto

Test Results Summary (Latest Run):
-----------------------------------
âœ“ 77 passed
âš  1 skipped (empty ticket validation - optional)
âœ— 0 failed
Total: 78 tests
Status: ALL CRITICAL TESTS PASSING

Key Test Insights:
------------------
â€¢ No summarization endpoint tests (endpoint doesn't exist)
â€¢ generate_summary_with_tags() tested but only used in test scenarios
â€¢ RAG service handles tag extraction (tested in integration tests)
â€¢ Database connection cleanup properly handled
â€¢ Real OpenAI/Pinecone calls in integration tests (requires API keys)

================================================================================
9. CONFIGURATION & DEPLOYMENT
================================================================================

9.1 ENVIRONMENT CONFIGURATION
------------------------------

Configuration File: .env (gitignored)
Template: .env.example (should be created)

Required Variables:
-------------------
OPENAI_API_KEY=sk-...              # OpenAI API key (required)
PINECONE_API_KEY=...               # Pinecone API key (required)
PINECONE_INDEX_NAME=support-docs   # Pinecone index name (required)

Optional Variables (with defaults):
------------------------------------
DB_URL=sqlite:///data/support.db   # Database connection URL
DOCS_DIR=data/docs                  # Knowledge base documents directory
VECTORSTORE_DIR=data/vectorstore    # Vector store persistence (unused currently)

Configuration Loading:
----------------------
â€¢ pydantic-settings for type-safe configuration
â€¢ Automatic .env file loading on import
â€¢ Environment variable override support
â€¢ Singleton pattern via @lru_cache decorator

Settings Class (app/config/settings.py):
-----------------------------------------
class Settings(BaseSettings):
    OPENAI_API_KEY: str                              # Required
    PINECONE_API_KEY: str                            # Required
    PINECONE_INDEX_NAME: str                         # Required
    DB_URL: str = "sqlite:///data/support.db"        # Default
    DOCS_DIR: str = "data/docs"                      # Default
    VECTORSTORE_DIR: str = "data/vectorstore"        # Default
    
    class Config:
        env_file = ".env"

Access Pattern:
---------------
from app.config.settings import get_settings

settings = get_settings()  # Returns cached singleton
api_key = settings.OPENAI_API_KEY

9.2 DEPENDENCY MANAGEMENT
--------------------------

Production Dependencies (requirements.txt):
-------------------------------------------
fastapi==0.115.5              # Web framework
uvicorn==0.32.1               # ASGI server
sqlalchemy==2.0.23            # ORM and database toolkit
pydantic==2.10.3              # Data validation
pydantic-settings==2.6.1      # Settings management
openai==1.3.7                 # OpenAI API client
pinecone-client==5.0.1        # Pinecone vector database client
python-dotenv==1.0.0          # Environment variable loading
streamlit==1.28.2             # UI framework (if used)

Total: 9 production dependencies

Development Dependencies (requirements-dev.txt):
------------------------------------------------
pytest==8.3.4                 # Testing framework
pytest-mock==3.14.0           # Mocking utilities
pytest-asyncio==0.25.3        # Async test support
pytest-xdist==3.6.1           # Parallel test execution
pytest-repeat==0.9.3          # Repeat flaky tests
httpx                         # HTTP client for testing
black                         # Code formatting
flake8                        # Linting

Installation:
-------------
# Production only
pip install -r requirements.txt

# Development (includes production)
pip install -r requirements.txt -r requirements-dev.txt

9.3 LOCAL DEVELOPMENT SETUP
----------------------------

Step 1: Clone and Navigate
---------------------------
git clone <repository>
cd support_desk_assistant-1

Step 2: Create Virtual Environment
-----------------------------------
python3 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

Step 3: Install Dependencies
-----------------------------
pip install --upgrade pip
pip install -r requirements.txt
pip install -r requirements-dev.txt

Step 4: Configure Environment
------------------------------
# Create .env file
cat > .env << EOF
OPENAI_API_KEY=sk-your-key-here
PINECONE_API_KEY=your-pinecone-key
PINECONE_INDEX_NAME=support-docs
DB_URL=sqlite:///data/support.db
DOCS_DIR=data/docs
EOF

Step 5: Initialize Database
----------------------------
# Database is auto-created on first run
# Tables created by init_db() in app startup

Step 6: Ingest Documents (Optional)
------------------------------------
# Place .txt or .md files in data/docs/
python scripts/ingest_docs.py

Step 7: Start Development Server
---------------------------------
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Server runs at: http://localhost:8000
# API docs at: http://localhost:8000/docs

Makefile Commands:
------------------
make ensure-venv          # Create virtual environment
make requirements         # Install production dependencies
make requirements-dev     # Install all dependencies
make run-api              # Start API server
make run-ingest           # Run document ingestion
make clean                # Clean Python caches

9.4 PRODUCTION DEPLOYMENT
--------------------------

Recommended Architecture:
-------------------------
â€¢ Container: Docker with Python 3.10+ slim image
â€¢ Reverse Proxy: Nginx with SSL/TLS (Let's Encrypt)
â€¢ Database: SQLite (for low traffic) or migrate to PostgreSQL
â€¢ Vector Store: Pinecone serverless (already cloud-based)
â€¢ Secrets Management: AWS Secrets Manager, HashiCorp Vault, or Kubernetes Secrets
â€¢ Logging: Structured JSON logs to stdout/stderr
â€¢ Monitoring: Health check endpoint + metrics endpoint

Environment Setup:
------------------
â€¢ Use environment variables (not .env file)
â€¢ Secret injection via orchestrator
â€¢ Read-only filesystem where possible
â€¢ Non-root user in container

Scaling Considerations:
-----------------------
â€¢ SQLite suitable for < 100 req/sec
â€¢ For higher load: Migrate to PostgreSQL
â€¢ Horizontal scaling: Stateless app (singleton services OK with caching)
â€¢ Database connection pooling: Enable for PostgreSQL

Health Monitoring:
------------------
Endpoint: GET /health
Response: {"status": "healthy", "version": "0.1.0"}
Use for:
â€¢ Load balancer health checks
â€¢ Kubernetes liveness/readiness probes
â€¢ Uptime monitoring

Performance Metrics to Track:
------------------------------
â€¢ API response times (p50, p95, p99)
â€¢ Database query latency
â€¢ OpenAI API latency (embedding + completion)
â€¢ Pinecone query latency
â€¢ Error rates (4xx, 5xx)
â€¢ Token usage (cost tracking)
â€¢ Concurrent requests
â€¢ Database connections

Logging Strategy:
-----------------
â€¢ Structured logging: JSON format
â€¢ Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
â€¢ Include: timestamp, level, message, context
â€¢ Log to stdout/stderr for container orchestration
â€¢ Centralized logging: ELK, CloudWatch, Datadog

Security Considerations:
------------------------
â€¢ API key rotation policy
â€¢ Rate limiting (not implemented yet)
â€¢ Input sanitization (Pydantic handles this)
â€¢ HTTPS only in production
â€¢ CORS configuration if needed
â€¢ Dependency vulnerability scanning

Backup Strategy:
----------------
â€¢ Database: Regular SQLite file backups
â€¢ Pinecone: Vectors persisted in cloud (auto-backup)
â€¢ Configuration: Version controlled .env.example

9.5 DEPLOYMENT CHECKLIST
-------------------------

Pre-Deployment:
---------------
â˜ All tests passing (78 tests)
â˜ Environment variables configured
â˜ API keys validated
â˜ Database initialized
â˜ Documents ingested to Pinecone
â˜ Health check endpoint responding
â˜ Dependencies up to date
â˜ Security scan completed

Production Configuration:
--------------------------
â˜ HTTPS enabled
â˜ CORS configured (if needed)
â˜ Rate limiting enabled
â˜ Logging configured
â˜ Monitoring/alerting set up
â˜ Backup strategy in place
â˜ Secrets properly managed
â˜ Non-root user in container

Post-Deployment:
----------------
â˜ Health check verified
â˜ Smoke tests passed
â˜ Monitoring dashboards checked
â˜ Error rates normal
â˜ API response times acceptable
â˜ Documentation updated

================================================================================
10. COMPLETE DATA FLOWS
================================================================================

10.1 DOCUMENT INGESTION WORKFLOW
---------------------------------

Purpose: Load knowledge base documents into Pinecone vector store

Script: scripts/ingest_docs.py

Step-by-Step Flow:
------------------
1. Script Initialization
   - Load settings (DOCS_DIR, Pinecone config)
   - Initialize VectorStoreClient (connects to Pinecone)
   - Initialize OpenAI client (for embeddings)

2. Document Discovery
   - Scan data/docs/ directory
   - Find all .txt and .md files
   - Read file contents

3. Document Chunking
   - Split documents into ~500 character chunks
   - Preserve context within chunks
   - Generate unique IDs or use filenames

4. Embedding Generation
   - For each chunk: call OpenAI embedding API
   - Model: text-embedding-ada-002
   - Output: 1536-dimensional vectors

5. Metadata Preparation
   - For each chunk: create metadata dict
   - Include: {"source": "filename.txt", "text": "chunk content"}

6. Pinecone Upsertion
   - Batch upsert vectors to Pinecone
   - Vector ID, embedding, metadata
   - Confirm successful ingestion

7. Summary Report
   - Print number of documents processed
   - Print number of chunks created
   - Print total vectors upserted

Usage:
------
python scripts/ingest_docs.py

Output Example:
---------------
Loaded 5 documents from data/docs/
Created 23 chunks
Generated embeddings for 23 chunks
Upserted 23 vectors to Pinecone index 'support-docs'
âœ“ Ingestion complete!

10.2 TICKET PROCESSING FLOW (DETAILED)
---------------------------------------

Complete end-to-end flow for ticket processing.

STEP 1: CLIENT REQUEST
-----------------------
POST /api/v1/tickets/agent
Content-Type: application/json
Body: 
{
  "ticket": "I forgot my password and can't access my account"
}

STEP 2: API LAYER (app/api/v1/endpoints.py)
--------------------------------------------
â€¢ FastAPI receives request
â€¢ Validates request body against TicketAgentRequest schema
â€¢ Injects dependencies:
  - db: Database session (via get_db)
  - agent: TicketAgentService (via get_ticket_agent)
â€¢ Calls: agent.process_ticket(db=db, text=request.ticket)

STEP 3: WORKFLOW ORCHESTRATION (app/core/workflows/ticket_workflow.py)
-----------------------------------------------------------------------
TicketAgentService.process_ticket()

3a. Call RAG Service
   â€¢ Invokes: self._rag_service.answer(text)
   â€¢ Passes ticket text to RAG
   â€¢ Waits for result

STEP 4: RAG SERVICE (app/core/services/rag_service.py)
-------------------------------------------------------
RagService.answer()

4a. Vector Store Query
   â€¢ Calls: self._vectorstore.query_similar(query_text, top_k=5)
   â€¢ Pinecone searches for similar documents
   â€¢ Returns: List of matches with scores and metadata

4b. Context Building
   â€¢ Extracts text from matched documents
   â€¢ Formats as: ["1. [doc1.txt] snippet...", "2. [doc2.txt] snippet..."]
   â€¢ Creates context_chunks list

4c. LLM Generation
   â€¢ Calls: self._openai_client.generate_rag_response(query, context_chunks)
   â€¢ Uses structured prompt from RagPrompts
   â€¢ OpenAI returns JSON: {answer, tags, confidence}
   â€¢ Parses response

4d. Return Result
   â€¢ Returns to TicketAgentService:
     {
       "answer": "To reset your password...",
       "tags": ["password", "account", "authentication"],
       "confidence": "high",
       "sources": [...]
     }

STEP 5: ACTION DETERMINATION (ticket_workflow.py)
--------------------------------------------------
Back in TicketAgentService.process_ticket()

5a. Extract Results
   â€¢ answer = rag_result.get("answer", "")
   â€¢ tags = rag_result.get("tags", [])
   â€¢ confidence = rag_result.get("confidence", "low")

5b. Decide Action
   â€¢ IF answer exists AND not "INSUFFICIENT_CONTEXT":
       action = "reply"
       reason = "Generated reply using knowledge base context via RAG."
   â€¢ ELSE:
       action = "escalate"
       reason = "Knowledge base lacks sufficient information; escalating to human agent."

STEP 6: DATABASE PERSISTENCE (app/infrastructure/repositories/ticket_repository.py)
------------------------------------------------------------------------------------
ticket_repository.create_ticket()

6a. Create Ticket ORM Object
   â€¢ ticket = Ticket(
       text=text,
       action=action,
       reply=answer if action == "reply" else None,
       tags=",".join(tags),  # Convert list to comma-separated string
       reason=reason,
       human_label=None,
       created_at=auto-generated
     )

6b. Database Operations
   â€¢ db.add(ticket)
   â€¢ db.commit()
   â€¢ db.refresh(ticket)  # Get ID and created_at

6c. Return Ticket
   â€¢ Returns: Ticket ORM object with ID

STEP 7: RESPONSE CONSTRUCTION (ticket_workflow.py)
---------------------------------------------------
Build response dict:
{
  "id": ticket.id,
  "action": ticket.action,
  "reply": ticket.reply,
  "tags": tags,  # As list
  "reason": ticket.reason
}

STEP 8: API RESPONSE (endpoints.py)
------------------------------------
â€¢ Construct TicketAgentResponse from result dict
â€¢ Return to client

STEP 9: CLIENT RECEIVES RESPONSE
---------------------------------
HTTP/1.1 200 OK
Content-Type: application/json

{
  "id": 42,
  "action": "reply",
  "reply": "To reset your password:\n1. Go to the login page\n2. Click 'Forgot Password'...",
  "reason": "Generated reply using knowledge base context via RAG.",
  "tags": ["password", "account", "authentication"]
}

TIMING BREAKDOWN (APPROXIMATE)
-------------------------------
â€¢ API validation: < 1ms
â€¢ RAG query (total): 600-1700ms
  - Embedding generation: 50ms
  - Pinecone search: 50-100ms
  - OpenAI chat completion: 500-1500ms
â€¢ Database insert: 5-10ms
â€¢ Response construction: < 1ms

TOTAL: ~600-2000ms typical

10.3 RAG QUERY FLOW (DETAILED)
-------------------------------

Standalone RAG query via POST /api/v1/rag/query

INPUT:
------
POST /api/v1/rag/query
{
  "query": "How do I reset my password?"
}

STEP 1: ENDPOINT VALIDATION
----------------------------
â€¢ Validate query is non-empty
â€¢ Inject RagService dependency

STEP 2: RAG SERVICE CALL
-------------------------
rag_service.answer(request.query)

STEP 3: EMBEDDING GENERATION
-----------------------------
â€¢ OpenAI API call
â€¢ Model: text-embedding-ada-002
â€¢ Input: "How do I reset my password?"
â€¢ Output: [1536 floats]
â€¢ Time: ~50ms

STEP 4: VECTOR SIMILARITY SEARCH
---------------------------------
â€¢ Pinecone query with embedding
â€¢ Metric: Cosine similarity
â€¢ top_k: 5 (retrieve 5 most similar)
â€¢ Returns: Matches with scores (0.0-1.0) and metadata

Example Match:
{
  "id": "doc_password_reset_chunk_1",
  "score": 0.92,
  "metadata": {
    "source": "password_reset.txt",
    "text": "To reset your password, navigate to..."
  }
}

Time: ~50-100ms

STEP 5: CONTEXT ASSEMBLY
-------------------------
Build context string from matches:

Context:
1. [password_reset.txt] To reset your password, navigate to the login page and click "Forgot Password"...
2. [account_security.txt] Account recovery procedures require email verification...
3. [faq.txt] Frequently asked questions about password resets...
4. [user_guide.txt] For security reasons, passwords must be reset using...
5. [troubleshooting.txt] If you cannot receive the password reset email...

STEP 6: PROMPT CONSTRUCTION
----------------------------
System Prompt (from RagPrompts.SYSTEM_PROMPT_WITH_TAGS):
"You are a helpful support assistant. Answer questions using the provided context..."

User Prompt:
"""
Context:
[assembled context from step 5]

Question: How do I reset my password?

Instructions: Provide a helpful answer based on the context. If context is insufficient, respond with "INSUFFICIENT_CONTEXT".
Include "tags", "answer", and "confidence" in JSON format.
"""

STEP 7: LLM GENERATION
----------------------
â€¢ OpenAI GPT-4o-mini API call
â€¢ Temperature: 0.7
â€¢ Expected output: JSON
â€¢ Structured output parsing

Raw LLM Response:
```json
{
  "answer": "To reset your password:\n1. Go to the login page\n2. Click 'Forgot Password'\n3. Enter your email address\n4. Check your email for a reset link\n5. Follow the link and create a new password\n\nFor security reasons, passwords must meet minimum requirements.",
  "tags": ["password", "reset", "authentication", "account"],
  "confidence": "high"
}
```

Time: ~500-1500ms

STEP 8: RESPONSE PARSING
-------------------------
â€¢ Parse JSON from LLM
â€¢ Validate structure with PromptValidator
â€¢ Fallback to plain text if parsing fails

Validated Result:
{
  "answer": "To reset your password...",
  "tags": ["password", "reset", "authentication", "account"],
  "confidence": "high",
  "sources": [
    {"id": "...", "score": 0.92, "metadata": {...}},
    ...
  ]
}

STEP 9: ENDPOINT RESPONSE CONSTRUCTION
---------------------------------------
Convert to RagQueryResponse:
â€¢ Extract answer
â€¢ Extract sources (doc_name, snippet)

STEP 10: CLIENT RECEIVES RESPONSE
----------------------------------
HTTP/1.1 200 OK
{
  "answer": "To reset your password:\n1. Go to the login page\n2. Click 'Forgot Password'...",
  "sources": [
    {
      "doc_name": "password_reset.txt",
      "snippet": "To reset your password, navigate to the login page..."
    },
    {
      "doc_name": "account_security.txt",
      "snippet": "Account recovery procedures require email verification..."
    }
  ]
}

TOTAL TIME: ~600-1700ms

10.4 FEEDBACK LOOP WORKFLOW
----------------------------

Purpose: Human-in-the-loop for model improvement

STEP 1: Human Reviews Ticket
-----------------------------
â€¢ Admin/agent reviews ticket #42
â€¢ Evaluates AI decision and response
â€¢ Decides on feedback label

STEP 2: Submit Feedback
------------------------
POST /api/v1/tickets/feedback
{
  "ticket_id": 42,
  "human_label": "correct"
}

STEP 3: Database Update
------------------------
â€¢ ticket_repository.update_ticket_feedback(db, 42, "correct")
â€¢ SQL: UPDATE tickets SET human_label = 'correct' WHERE id = 42
â€¢ Returns: Updated Ticket object

STEP 4: Response
-----------------
Returns complete TicketRecord with updated human_label

Future Enhancements:
--------------------
â€¢ Aggregate feedback statistics
â€¢ Identify patterns in incorrect decisions
â€¢ Fine-tune prompts based on feedback
â€¢ A/B test different prompt strategies
â€¢ Export feedback data for model retraining

10.5 ERROR HANDLING FLOWS
--------------------------

ERROR TYPE 1: VALIDATION ERRORS (422)
--------------------------------------
Trigger: Invalid request body
Example: Empty ticket text, malformed JSON

Flow:
â€¢ Pydantic validation fails
â€¢ FastAPI returns 422 with detailed errors
â€¢ Response: {"detail": [{"loc": [...], "msg": "...", "type": "..."}]}

ERROR TYPE 2: NOT FOUND ERRORS (404)
-------------------------------------
Trigger: Ticket ID doesn't exist
Example: POST /api/v1/tickets/feedback with invalid ticket_id

Flow:
â€¢ Repository returns None
â€¢ Endpoint raises HTTPException(404)
â€¢ Response: {"detail": "Ticket not found"}

ERROR TYPE 3: EXTERNAL API ERRORS (500)
----------------------------------------
Trigger: OpenAI or Pinecone API failure

Flow:
â€¢ Exception caught in service layer
â€¢ Logged to stderr
â€¢ Returns 500 Internal Server Error
â€¢ Response: {"detail": "Internal server error"}

Retry Strategy:
â€¢ OpenAI SDK has built-in retries
â€¢ Pinecone SDK has built-in retries
â€¢ Application layer: No explicit retry (fails fast)

ERROR TYPE 4: DATABASE ERRORS (500)
------------------------------------
Trigger: Database connection failure, constraint violation

Flow:
â€¢ SQLAlchemy exception raised
â€¢ Transaction rolled back
â€¢ Error logged
â€¢ Returns 500 Internal Server Error

ERROR TYPE 5: JSON PARSING ERRORS (Internal)
---------------------------------------------
Trigger: LLM returns invalid JSON

Flow:
â€¢ json.loads() raises JSONDecodeError
â€¢ Fallback to safe default: {"answer": raw_text, "tags": [], "confidence": "low"}
â€¢ No error to client (graceful degradation)

================================================================================
CONCLUSION
================================================================================

The AI Support Desk Assistant is a production-ready application with:

CURRENT ARCHITECTURE HIGHLIGHTS:
---------------------------------
âœ“ Clean layered architecture (API â†’ Core â†’ Infrastructure)
âœ“ Single efficient RAG call (no separate summarization)
âœ“ 4 REST endpoints (RAG query, ticket processing, feedback, list)
âœ“ Integrated tag extraction within RAG workflow
âœ“ 78 comprehensive tests (77 passing, 1 skipped)
âœ“ SQLite database with proper ORM
âœ“ Pinecone serverless vector store
âœ“ OpenAI GPT-4o-mini for LLM
âœ“ Dependency injection for testability
âœ“ Type-safe configuration with pydantic-settings

KEY TECHNICAL DECISIONS:
-------------------------
â€¢ No /summarise endpoint - Tags extracted during RAG processing
â€¢ No separate summariser service - Consolidated into RAG for efficiency
â€¢ Single LLM call per ticket - Reduces latency and cost
â€¢ Singleton pattern for services - Reduces initialization overhead
â€¢ SQLite with NullPool - Suitable for development and low-traffic production
â€¢ Serverless Pinecone - Auto-scaling, pay-per-use

PRODUCTION READINESS:
---------------------
âœ“ All critical tests passing
âœ“ Health check endpoint
âœ“ Error handling and validation
âœ“ Database persistence
âœ“ External API integrations working
âœ“ Configuration management
âœ“ Documentation complete

DEPLOYMENT STATUS: READY
-------------------------
The application can be deployed to production with:
â€¢ Proper environment variable configuration
â€¢ API keys provisioned
â€¢ Documents ingested to Pinecone
â€¢ Database initialized
â€¢ Health checks configured
â€¢ Monitoring setup

================================================================================
END OF DOCUMENT
================================================================================
